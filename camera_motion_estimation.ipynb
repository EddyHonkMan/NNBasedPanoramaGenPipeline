{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VQF9cOrF-EH-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import shelve\n",
    "from carvekit.api.high import HiInterface\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from carvekit.api.interface import Interface\n",
    "from carvekit.ml.wrap.fba_matting import FBAMatting\n",
    "from carvekit.ml.wrap.tracer_b7 import TracerUniversalB7\n",
    "from carvekit.ml.wrap.u2net import U2NET\n",
    "from carvekit.pipelines.postprocessing import MattingMethod\n",
    "from carvekit.pipelines.preprocessing import PreprocessingStub\n",
    "from carvekit.trimap.generator import TrimapGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manual\n",
    "# Check doc strings for more information\n",
    "object_type = \"object\"\n",
    "_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if object_type == 'hair_like':\n",
    "    seg_net = U2NET(device=_device, batch_size=5,\n",
    "                    input_image_size=320, fp16=True)\n",
    "else:\n",
    "    seg_net = TracerUniversalB7(\n",
    "        device=_device, batch_size=5, input_image_size=640, fp16=True)\n",
    "\n",
    "\n",
    "fba = FBAMatting(device=_device,\n",
    "                 input_tensor_size=2048,\n",
    "                 batch_size=1)\n",
    "\n",
    "trimap = TrimapGenerator(prob_threshold=231,\n",
    "                         kernel_size=30,\n",
    "                         erosion_iters=5)\n",
    "\n",
    "preprocessing = PreprocessingStub()\n",
    "\n",
    "postprocessing = MattingMethod(matting_module=fba,\n",
    "                               trimap_generator=trimap,\n",
    "                               device=_device)\n",
    "interface = Interface(pre_pipe=preprocessing,\n",
    "                      post_pipe=postprocessing,\n",
    "                      seg_pipe=seg_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input video path\n",
    "DIR_PATH = 'videos'\n",
    "FILENAME = 'test1.mp4'\n",
    "INPUT_VIDEO_PATH = os.path.join(DIR_PATH, FILENAME)\n",
    "OUTPUT_PATH = 'out'\n",
    "\n",
    "OUTPUT_FOREGROUND_VIDEO_NAME = FILENAME.split('.')[0] + '_foreground.mp4'\n",
    "OUTPUT_BACKGROUND_VIDEO_NAME = FILENAME.split('.')[0] + '_background.mp4'\n",
    "OUTPUT_PANORAMA_IMG_NAME = FILENAME.split('.')[0] + '_panorama.png'\n",
    "HOLE_FILLED_BACKGROUND_VIDEO_NAME = FILENAME.split('.')[0] + '_filled_background_video.mp4'\n",
    "\n",
    "OUTPUT_FOREGROUND_VIDEO_PATH = os.path.join(OUTPUT_PATH, OUTPUT_FOREGROUND_VIDEO_NAME)\n",
    "OUTPUT_BACKGROUND_VIDEO_PATH = os.path.join(OUTPUT_PATH, OUTPUT_BACKGROUND_VIDEO_NAME)\n",
    "OUTPUT_PANORAMA_IMG_PATH = os.path.join(OUTPUT_PATH, OUTPUT_PANORAMA_IMG_NAME)\n",
    "HOLE_FILLED_BACKGROUND_VIDEO_PATH = os.path.join(OUTPUT_PATH, HOLE_FILLED_BACKGROUND_VIDEO_NAME)\n",
    "\n",
    "H_PERSIST_FILENAME = 'H_persist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_frames(path):\n",
    "    \"\"\"\n",
    "    return video frames\n",
    "    \"\"\"\n",
    "    cap = cv.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Open video failed!\")\n",
    "\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            break\n",
    "\n",
    "        frames.append(frame)\n",
    "        \n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture(INPUT_VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Open video failed!\")\n",
    "\n",
    "fps = int(cap.get(cv.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "ret, img1 = cap.read()\n",
    "ret, img2 = cap.read()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
    "indice = gray2 > 0\n",
    "print(indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1[indice] = img2[indice]\n",
    "cv.imshow('asdf', img1)\n",
    "cv.imshow('qwer', img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_foreground_labels(path, early_quit_frame_number=math.inf, early_quit_time=None):\n",
    "    cap = cv.VideoCapture(path)\n",
    "    if not cap.isOpened:\n",
    "        raise IOError(\"Open video failed!\")\n",
    "\n",
    "    foreground_labels = []\n",
    "    startTime = time.time()\n",
    "    try:\n",
    "        for _ in tqdm(range(int(min(cap.get(cv.CAP_PROP_FRAME_COUNT), early_quit_frame_number)))):\n",
    "            if early_quit_time and time.time() - startTime > early_quit_time:\n",
    "                break\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                raise IOError(\"Read frame failed!\")\n",
    "                \n",
    "            frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame, mode=\"RGB\")\n",
    "            resImg = interface([image])[0]\n",
    "            foreground = np.asarray(resImg)\n",
    "            foreground_label = set()\n",
    "            for i in range(len(foreground)):\n",
    "                for j in range(len(foreground[0])):\n",
    "                    if foreground[i][j][-1] != 0:\n",
    "                        foreground_label.add((i, j))\n",
    "            foreground_labels.append(foreground_label)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')    \n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    return foreground_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # compute foreground labels\n",
    "# foreground_labels = get_foreground_labels(INPUT_VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # save foreground labels\n",
    "# foreground_label_persistence_file = '{}_foreground_labels.npy'.format(FILENAME.split('.')[0])\n",
    "# np.save(foreground_label_persistence_file, [list(label) for label in foreground_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load foreground_labels\n",
    "# foreground_label_persistence_file = '{}_foreground_labels.npy'.format(FILENAME.split('.')[0])\n",
    "# foreground_labels = np.load(foreground_label_persistence_file, allow_pickle=True)\n",
    "# # convert foreground_labels to list of set\n",
    "# foreground_labels = [set(_) for _ in foreground_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_foreground_background_videos(foreground_labels):\n",
    "    if not os.path.exists('out'):\n",
    "        os.makedirs('out')\n",
    "\n",
    "    cap = cv.VideoCapture(INPUT_VIDEO_PATH)\n",
    "    if not cap.isOpened:\n",
    "        raise IOError(\"Open video failed!\")\n",
    "\n",
    "    foreground_out = cv.VideoWriter(OUTPUT_FOREGROUND_VIDEO_PATH, cv.VideoWriter_fourcc(*'XVID'), int(cap.get(cv.CAP_PROP_FPS)),\n",
    "                                (int(cap.get(cv.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))))\n",
    "    background_out = cv.VideoWriter(OUTPUT_BACKGROUND_VIDEO_PATH, cv.VideoWriter_fourcc(*'XVID'), int(cap.get(cv.CAP_PROP_FPS)),\n",
    "                                (int(cap.get(cv.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))))\n",
    "    if not foreground_out.isOpened() or not background_out.isOpened():\n",
    "        raise IOError(\"Init videoWriter failed!\")\n",
    "\n",
    "    try:\n",
    "        for i in tqdm(range(len(foreground_labels))):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                raise IOError(\"Read frame failed!\")\n",
    "                \n",
    "            label = foreground_labels[i]\n",
    "            foreground = np.zeros_like(frame)\n",
    "            foreground.fill(255)\n",
    "            for (j, k) in label:\n",
    "                foreground[j][k] = frame[j][k]\n",
    "                frame[j][k] = [255,255,255]\n",
    "\n",
    "            foreground_out.write(foreground.copy())\n",
    "            background_out.write(frame.copy())\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')    \n",
    "\n",
    "    cap.release()\n",
    "    foreground_out.release()\n",
    "    background_out.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generate_foreground_background_videos(foreground_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_H_matrix(img1, img2):\n",
    "    # minimum number of matches we want find between these two images\n",
    "    MIN_MATCH_COUNT = 10\n",
    "\n",
    "    # initiate feature detector, currently use SIFT, may try orb later\n",
    "    sift = cv.SIFT_create()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(cv.cvtColor(img1, cv.COLOR_BGR2GRAY),None)\n",
    "    kp2, des2 = sift.detectAndCompute(cv.cvtColor(img2, cv.COLOR_BGR2GRAY),None)\n",
    "\n",
    "\n",
    "    # BF_Matcher = cv.BFMatcher()\n",
    "    # InitialMatches = BF_Matcher.knnMatch(des1,des2,k=2)\n",
    "    # good = []\n",
    "    # for m, n in InitialMatches:\n",
    "    #     if m.distance <0.75 * n.distance:\n",
    "    #         good.append([m])\n",
    "    # if len(good) < 4:\n",
    "    #     raise ValueError('asdfasdfasdfasdgdfagfdsg')\n",
    "    #     exit(0)\n",
    "    # src_pts = []\n",
    "    # dst_pts = []\n",
    "    # for m in good:\n",
    "    #     src_pts.append(kp1[m[0].queryIdx].pt)\n",
    "    #     dst_pts.append(kp2[m[0].trainIdx].pt)\n",
    "    \n",
    "    # src_pts = np.float32(src_pts)\n",
    "    # dst_pts = np.float32(dst_pts)\n",
    "    # H, _ = cv.findHomography(dst_pts, src_pts, cv.RANSAC, 4.0)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        H, _ = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "        # matchesMask = mask.ravel().tolist()\n",
    "        # h,w = img1.shape\n",
    "        # pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "        # dst = cv.perspectiveTransform(pts,H)\n",
    "        # img2 = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)\n",
    "    else:\n",
    "        raise ValueError( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # matchesMask = None\n",
    "\n",
    "    # draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "    #                singlePointColor = None,\n",
    "    #                matchesMask = matchesMask, # draw only inliers\n",
    "    #                flags = 2)\n",
    "    # img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "    # plt.imshow(img3, 'gray'),plt.show()\n",
    "\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compute all H per gap\n",
    "# Hs = get_all_H_matrix_per_step(INPUT_VIDEO_PATH, gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save Hs\n",
    "# np.save('{}_all_H.npy'.format(FILENAME.split('.')[0]), Hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load Hs\n",
    "# Hs = np.load('{}_all_H.npy'.format(FILENAME.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fill_holes_with_H_cached(step, grap, max_iteration_depth, persist_file, start_index = 0, end_index = 10000000):\n",
    "    with shelve.open(writeback=True, filename=persist_file) as d:\n",
    "        if FILENAME not in d:\n",
    "            d[FILENAME] = {}\n",
    "        m = d[FILENAME]\n",
    "        return fill_holes(step, grap, max_iteration_depth, m, start_index, end_index)\n",
    "\n",
    "\n",
    "# fill per step frame's hole using adjacent frames per gap, with max_iteration_depth\n",
    "def fill_holes(step, gap, max_iteration_depth, m = None, start_index = 0, end_index = 10000000):\n",
    "    \"\"\"\n",
    "    :param step: controls the distance between each two frames for which we are filling their holes\n",
    "    :param gap: is the distance unit between target frame and current frame when filling hole\n",
    "    :param max_iteration_depth: we iterate on one frame for at most max_iteration_depth, even when we haven't filled the hole completely. This is experimental feature to control the time complexity of the method\n",
    "    :param m: a dictionary to persist H matrix between (i, j) frames\n",
    "    :return: a list of hole_filled frames\n",
    "    \"\"\"\n",
    "    frames = read_frames(OUTPUT_BACKGROUND_VIDEO_PATH)\n",
    "    res = []\n",
    "    all_filled_count = 0\n",
    "    count = 0\n",
    "    end_index = min(len(frames), end_index)\n",
    "\n",
    "    if len(frames) != len(foreground_labels):\n",
    "        raise IndexError(\"foreground_labels length not equal to frames!\")\n",
    "\n",
    "    if len(frames) < 1 + max_iteration_depth * gap:\n",
    "        raise IndexError(\"video number of frames too small!\")\n",
    "\n",
    "    for i in tqdm(range(start_index, end_index, step)):\n",
    "        count += 1\n",
    "        cur_label = foreground_labels[i].copy()\n",
    "        iteration_depth = 0\n",
    "        left = 1\n",
    "        right = 1\n",
    "        # True means right, False means left\n",
    "        last_direction = False\n",
    "        # print('at frame {}'.format(i))\n",
    "        while len(cur_label) > 0 and iteration_depth < max_iteration_depth:\n",
    "            # we follow right, left, right, left pattern\n",
    "            target_index = i + right * gap if not last_direction else i - left * gap\n",
    "\n",
    "            if 0 <= target_index < len(frames):\n",
    "                # print('cur_label {} remaining to fill'.format(len(cur_label)))\n",
    "                target_label = foreground_labels[target_index]\n",
    "                srcs = [list(t) for t in cur_label]\n",
    "                # point x = j, y = i, so reverse below in a[::-1]\n",
    "                #perspectivetransform needs 3 dimensions, so we must manually wrap a nonsense dimension to make below 1 * N * 2\n",
    "                srcpts = np.array([[a[::-1] for a in srcs]]).astype(np.float32)\n",
    "                if m is not None:\n",
    "                    if (i, target_index) in m:\n",
    "                        H = m[(i, target_index)]\n",
    "                    else:\n",
    "                        H = get_H_matrix(frames[i], frames[target_index])\n",
    "                        m[(i, target_index)] = H\n",
    "                else:\n",
    "                    H = get_H_matrix(frames[i], frames[target_index])\n",
    "                dstpts = np.rint(cv.perspectiveTransform(srcpts, H)[0]).astype(int)\n",
    "                for (x, y), (corresponding_x, corresponding_y) in zip(np.rint(srcpts[0]).astype(int), dstpts):\n",
    "                    if (corresponding_y, corresponding_x) not in target_label and 0 <= corresponding_x < width and 0 <= corresponding_y < height:\n",
    "                        cur_label.remove((y, x))\n",
    "                        frames[i][y][x] = frames[target_index][corresponding_y][corresponding_x]\n",
    "                iteration_depth += 1\n",
    "\n",
    "                # if this time to right\n",
    "                if not last_direction:\n",
    "                    right += 1\n",
    "                else:\n",
    "                    left += 1\n",
    "\n",
    "            last_direction = not last_direction\n",
    "\n",
    "        res.append(frames[i])\n",
    "        # print(\"cur_label finished, good to go!\" if len(cur_label) == 0 else 'cur_label {} not filled, go anyway'.format(len(cur_label)))\n",
    "        all_filled_count += 1 if len(cur_label) == 0 else 0\n",
    "\n",
    "    print('total number of frames filled: {}'.format(count))\n",
    "    print('all_filled frames count: {}'.format(all_filled_count))\n",
    "    print('{} frames not fully filled'.format(count - all_filled_count))\n",
    "    return res\n",
    "\n",
    "\n",
    "# filled_frames = fill_holes_with_H_cached(60, 6, 6, persist_file=H_PERSIST_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill hole for all frames in range(start_index : end_index : 1), end_index frame is not included\n",
    "def generate_hole_filled_background_images_between_indices(folder_path, start_index, end_index):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "    filled_frames = fill_holes_with_H_cached(1, 6, 30, persist_file=H_PERSIST_FILENAME, start_index = start_index, end_index = end_index)\n",
    "    for i in range(len(filled_frames)):\n",
    "        cv.imwrite(os.path.join(folder_path, '{}_background_{}.jpg'.format(FILENAME.split('.')[0], i + start_index)), filled_frames[i])\n",
    "\n",
    "# generate_hole_filled_background_images_between_indices('out_images', 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.path.join('out_images', '{}_background_{}.jpg'.format(FILENAME.split('.')[0], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(len(filled_frames))\n",
    "# for f in filled_frames:\n",
    "#     cv.imshow('asdf', f)\n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWindows()\n",
    "#     cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H = get_H_matrix(filled_frames[1], filled_frames[0])\n",
    "# cv.imshow('src', filled_frames[1])\n",
    "# cv.imshow('dst', filled_frames[0])\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()\n",
    "# warped = cv.warpPerspective(filled_frames[1], H, (width, height))\n",
    "# cv.imshow('src warped', warped)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpPerspectivePadded(\n",
    "        src, dst, M,\n",
    "        flags=cv.INTER_LINEAR,\n",
    "        borderMode=cv.BORDER_CONSTANT,\n",
    "        borderValue=0):\n",
    "    assert M.shape == (3, 3), \\\n",
    "        'Perspective transformation shape should be (3, 3).\\n' \\\n",
    "        + 'Use warpAffinePadded() for (2, 3) affine transformations.'\n",
    "\n",
    "    M = M / M[2, 2]  # ensure a legal homography\n",
    "    if flags in (cv.WARP_INVERSE_MAP,\n",
    "                 cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    "                 cv.INTER_NEAREST + cv.WARP_INVERSE_MAP):\n",
    "        M = cv.invert(M)[1]\n",
    "        flags -= cv.WARP_INVERSE_MAP\n",
    "\n",
    "    # it is enough to find where the corners of the image go to find\n",
    "    # the padding bounds; points in clockwise order from origin\n",
    "    src_h, src_w = src.shape[:2]\n",
    "    lin_homg_pts = np.array([\n",
    "        [0, src_w, src_w, 0],\n",
    "        [0, 0, src_h, src_h],\n",
    "        [1, 1, 1, 1]])\n",
    "\n",
    "    # transform points\n",
    "    transf_lin_homg_pts = M.dot(lin_homg_pts)\n",
    "    transf_lin_homg_pts /= transf_lin_homg_pts[2, :]\n",
    "\n",
    "    # find min and max points\n",
    "    min_x = np.floor(np.min(transf_lin_homg_pts[0])).astype(int)\n",
    "    min_y = np.floor(np.min(transf_lin_homg_pts[1])).astype(int)\n",
    "    max_x = np.ceil(np.max(transf_lin_homg_pts[0])).astype(int)\n",
    "    max_y = np.ceil(np.max(transf_lin_homg_pts[1])).astype(int)\n",
    "\n",
    "    # add translation to the transformation matrix to shift to positive values\n",
    "    anchor_x, anchor_y = 0, 0\n",
    "    transl_transf = np.eye(3, 3)\n",
    "    if min_x < 0:\n",
    "        anchor_x = -min_x\n",
    "        transl_transf[0, 2] += anchor_x\n",
    "    if min_y < 0:\n",
    "        anchor_y = -min_y\n",
    "        transl_transf[1, 2] += anchor_y\n",
    "    shifted_transf = transl_transf.dot(M)\n",
    "    shifted_transf /= shifted_transf[2, 2]\n",
    "\n",
    "    # create padded destination image\n",
    "    dst_h, dst_w = dst.shape[:2]\n",
    "\n",
    "    padding = [anchor_y, max(max_y, dst_h) - dst_h,\n",
    "                  anchor_x, max(max_x, dst_w) - dst_w]\n",
    "\n",
    "    dst_padded = cv.copyMakeBorder(dst, *padding,\n",
    "                                    borderType=borderMode, value=borderValue)\n",
    "    \n",
    "    dst_pad_h, dst_pad_w = dst_padded.shape[:2]\n",
    "    src_warped = cv.warpPerspective(\n",
    "        src, shifted_transf, (dst_pad_w, dst_pad_h),\n",
    "        flags=flags, borderMode=borderMode, borderValue=borderValue)\n",
    "\n",
    "    return dst_padded, src_warped, padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch(dst, src, H, flags=cv.INTER_LINEAR,\n",
    "        borderMode=cv.BORDER_CONSTANT,\n",
    "        borderValue=0):\n",
    "    assert H.shape == (3,3)\n",
    "    H = H / H[2, 2]  # ensure a legal homography\n",
    "    src_h, src_w = src.shape[:2]\n",
    "    lin_homg_pts = np.array([\n",
    "        [0, src_w, src_w, 0],\n",
    "        [0, 0, src_h, src_h],\n",
    "        [1, 1, 1, 1]])\n",
    "        # transform points\n",
    "    transf_lin_homg_pts = H.dot(lin_homg_pts)\n",
    "    transf_lin_homg_pts /= transf_lin_homg_pts[2, :]\n",
    "\n",
    "    # find min and max points\n",
    "    min_x = np.floor(np.min(transf_lin_homg_pts[0])).astype(int)\n",
    "    min_y = np.floor(np.min(transf_lin_homg_pts[1])).astype(int)\n",
    "    max_x = np.ceil(np.max(transf_lin_homg_pts[0])).astype(int)\n",
    "    max_y = np.ceil(np.max(transf_lin_homg_pts[1])).astype(int)\n",
    "\n",
    "    # add translation to the transformation matrix to shift to positive values\n",
    "    anchor_x, anchor_y = 0, 0\n",
    "    transl_transf = np.eye(3, 3)\n",
    "    if min_x < 0:\n",
    "        anchor_x = -min_x\n",
    "        transl_transf[0, 2] += anchor_x\n",
    "    if min_y < 0:\n",
    "        anchor_y = -min_y\n",
    "        transl_transf[1, 2] += anchor_y\n",
    "    shifted_transf = transl_transf.dot(H)\n",
    "    shifted_transf /= shifted_transf[2, 2]\n",
    "\n",
    "    dst_h, dst_w = dst.shape[:2]\n",
    "    padding = [anchor_y, max(max_y, dst_h) - dst_h,\n",
    "                  anchor_x, max(max_x, dst_w) - dst_w]\n",
    "    \n",
    "    stitched_image = cv.warpPerspective(\n",
    "        src, shifted_transf, (dst_w + padding[2] + padding[3], dst_h + padding[0] + padding[1]),\n",
    "        flags=flags, borderMode=borderMode, borderValue=borderValue)\n",
    "    \n",
    "    for i in range(0, dst_h):\n",
    "        for j in range(0, dst_w):\n",
    "            if any(dst[i][j]):\n",
    "                stitched_image[i + padding[0]][j + padding[2]] = dst[i][j]\n",
    "\n",
    "    # for i in range(padding[0], padding[0] + dst_h):\n",
    "    #     for j in range(padding[2], padding[2] + dst_w):\n",
    "    #         if not any(stitched_image[i][j]):\n",
    "    #             stitched_image[i][j] = dst[i - padding[0]][j - padding[2]]\n",
    "    # stitched_image[padding[0]:padding[0] + dst_h, padding[2]:padding[2] + dst_w] = dst\n",
    "    return stitched_image, shifted_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need fix, issue introduced by my change, original was right\n",
    "def stitch_two_images(dst, src, old_padding, H):\n",
    "    print('old panorama shape:', dst.shape)\n",
    "    dst_padded, src_warped, tmp_padding = warpPerspectivePadded(src, dst, H)\n",
    "    new_padding = [max(a,b) for a,b in zip(tmp_padding, old_padding)]\n",
    "    if any([a > b for a, b in zip(new_padding, old_padding)]):\n",
    "        dst_padded = cv.copyMakeBorder(dst, *[max(a - b, 0) for a, b in zip(new_padding, old_padding)], borderType=cv.BORDER_CONSTANT, value=0)\n",
    "    # here we can rest assured that old_padding is always greater or equal to new_padding\n",
    "    print('old_padding:', old_padding, 'tmp_padding:', tmp_padding, 'new padding:', new_padding)\n",
    "    print('src wrapped shape:', src_warped.shape)\n",
    "    print('new panorama shape:', dst_padded.shape)\n",
    "    assert dst_padded.shape >= src_warped.shape\n",
    "    for i in range(len(src_warped)):\n",
    "        for j in range(len(src_warped[0])):\n",
    "            if any(src_warped[i][j]) and not any(dst_padded[i + new_padding[0] - tmp_padding[0]][j + new_padding[2] - tmp_padding[2]]):\n",
    "                dst_padded[i + new_padding[0] - tmp_padding[0]][j + new_padding[2] - tmp_padding[2]] = src_warped[i][j]\n",
    "    return dst_padded, new_padding\n",
    "\n",
    "# map src to dst using H, with dst's original padding parameter given for warped src to fill external hole in dst with new padding\n",
    "# this method requirs the dst image does not have padding, *conceptually*(i.e. if you view dst image's padding as its content, then you are free to go)\n",
    "def worker(dst, src, H):\n",
    "    dst_padded, src_warped, padding = warpPerspectivePadded(src, dst, H)\n",
    "    assert dst_padded.shape == src_warped.shape and len(padding) == 4\n",
    "    for i in range(len(src_warped)):\n",
    "        for j in range(len(src_warped[0])):\n",
    "            if i < padding[0] or i >= len(src_warped) - padding[1] or j < padding[2] or j >= len(src_warped[0]) - padding[3]:\n",
    "                dst_padded[i][j] = src_warped[i][j]\n",
    "    return dst_padded, padding\n",
    "\n",
    "# map src to dst using H, with dst's original padding parameter given for warped src to fill external hole in dst with new padding\n",
    "# this method requirs the dst image does not have padding, *conceptually*(i.e. if you view dst image's padding as its content, then you are free to go)\n",
    "def tmp_worker(dst, src, H):\n",
    "    dst_padded, src_warped, padding = warpPerspectivePadded(src, dst, H)\n",
    "    assert dst_padded.shape == src_warped.shape and len(padding) == 4\n",
    "    for i in range(len(src_warped)):\n",
    "        for j in range(len(src_warped[0])):\n",
    "            if any(src_warped[i][j]) and not any(dst_padded[i][j]):\n",
    "                dst_padded[i][j] = src_warped[i][j]\n",
    "    return dst_padded, padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lower resolution image for faster H matrix computation\n",
    "def scale_image(img, scale_factor=0.8):\n",
    "    return cv.resize(img, [int(round(img.shape[1] * scale_factor)), int(round(img.shape[0] * scale_factor))], interpolation=cv.INTER_LINEAR_EXACT)\n",
    "\n",
    "def scale_to_1920_1080(img):\n",
    "    return cv.resize(img,(1920, 1080), interpolation=cv.INTER_LINEAR_EXACT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_H_matrix_cached_version(i, j, i_frame, j_frame, m):\n",
    "    if ((i, j)) in m:\n",
    "        return m[(i, j)]\n",
    "    H = get_H_matrix(i_frame, j_frame)\n",
    "    m[(i, j)] = H\n",
    "    return H\n",
    "\n",
    "\n",
    "# H computed in this method would be persisted using shelve, would return panorama frame and its index\n",
    "def generate_panorama(step=10, original_frames=None, hole_filled_frames=None, right_cache=None, left_cache=None):\n",
    "    if original_frames is None:\n",
    "        original_frames = read_frames(INPUT_VIDEO_PATH)\n",
    "    if hole_filled_frames is None:\n",
    "        hole_filled_frames = read_frames(HOLE_FILLED_BACKGROUND_VIDEO_PATH)\n",
    "    if len(hole_filled_frames) != len(original_frames):\n",
    "        raise IndexError(\"original frames and hole_filled background frames have different length! {}, {}\".format(len(original_frames), len(hole_filled_frames)))\n",
    "    \n",
    "    try:\n",
    "        with shelve.open(writeback=True, filename=H_PERSIST_FILENAME) as d:\n",
    "            if FILENAME not in d:\n",
    "                d[FILENAME] = {}\n",
    "            m = d[FILENAME]\n",
    "            anchor_index = len(original_frames) // 2\n",
    "\n",
    "            # iterate from middle to right\n",
    "            right = len(original_frames) - 1\n",
    "            right_padded = hole_filled_frames[right].copy()\n",
    "            for i in tqdm(range(right, anchor_index + step, -step)):\n",
    "                H = get_H_matrix_cached_version(i, i - step, original_frames[i], original_frames[i - step], m)\n",
    "                right_padded, padding_from_right = worker(hole_filled_frames[i - step], right_padded, H)\n",
    "                if right_cache:\n",
    "                    right_cache.append(right_padded.copy())\n",
    "            r = i\n",
    "\n",
    "            # iterate from left to middle\n",
    "            left = 0\n",
    "            left_padded = hole_filled_frames[left].copy()\n",
    "            for i in tqdm(range(left, anchor_index - step, step)):\n",
    "                H = get_H_matrix_cached_version(i, i + step, original_frames[i], original_frames[i + step], m)\n",
    "                left_padded, padding_from_left = worker(hole_filled_frames[i + step], left_padded, H)\n",
    "                if left_cache:\n",
    "                    left_cache.append(left_padded.copy())\n",
    "            l = i\n",
    "\n",
    "            assert l < anchor_index < r\n",
    "\n",
    "            # now only left_padded, anchor frame and right_padded need to blend\n",
    "            # first blend right_padded with anchor\n",
    "            H = get_H_matrix_cached_version(r, anchor_index, original_frames[r], original_frames[anchor_index], m)\n",
    "            right_padded, padding_from_right = worker(hole_filled_frames[anchor_index], right_padded, H)\n",
    "            # then blend left_padded with above result\n",
    "            H = get_H_matrix_cached_version(l, anchor_index, original_frames[l], original_frames[anchor_index], m)\n",
    "            left_padded, padding_from_left = worker(right_padded, left_padded, H)\n",
    "\n",
    "            # return panorama and its final padding info\n",
    "            return left_padded, padding_from_left\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_panorama_from_middle_to_both_sides(shifted_H_persist, right_step = 10, left_step=10, original_frames=None, \n",
    "                    hole_filled_frames=None, right_cache=None, left_cache=None, clear_cache=False, anchor_index=-1):\n",
    "    if original_frames is None:\n",
    "        original_frames = read_frames(INPUT_VIDEO_PATH)\n",
    "    if hole_filled_frames is None:\n",
    "        hole_filled_frames = read_frames(HOLE_FILLED_BACKGROUND_VIDEO_PATH)\n",
    "    if len(hole_filled_frames) != len(original_frames):\n",
    "        raise IndexError(\"original frames and hole_filled background frames have different length! {}, {}\".format(len(original_frames), len(hole_filled_frames)))\n",
    "    \n",
    "    try:\n",
    "        with shelve.open(writeback=True, filename=H_PERSIST_FILENAME) as d:\n",
    "            # using original video H cache\n",
    "            if FILENAME not in d:\n",
    "                d[FILENAME] = {}\n",
    "            if 'original' not in d[FILENAME]:\n",
    "                d[FILENAME]['original'] = {}\n",
    "            m = d[FILENAME]['original']\n",
    "            anchor_index = len(original_frames) // 2 if anchor_index == -1 else anchor_index\n",
    "            if 'panorama{}'.format(anchor_index) not in d[FILENAME]:\n",
    "                d[FILENAME]['panorama{}'.format(anchor_index)] = {}\n",
    "            panorama_cache = d[FILENAME]['panorama{}'.format(anchor_index)]\n",
    "\n",
    "            if clear_cache:\n",
    "                m.clear()\n",
    "                panorama_cache.clear()\n",
    "\n",
    "            dst = hole_filled_frames[anchor_index].copy()\n",
    "            left = anchor_index - left_step\n",
    "            right = anchor_index + right_step\n",
    "            last_direction = False\n",
    "            padding = [0] * 4\n",
    "            count = 1\n",
    "\n",
    "            while left >= 0 or right < len(original_frames):\n",
    "                print('iteration {}, time: {}'.format(count, time.time()))\n",
    "                count += 1\n",
    "                # right, left, right, left pattern\n",
    "                if not last_direction:\n",
    "                    if right < len(original_frames):\n",
    "                        if right in panorama_cache:\n",
    "                            print('cache hit')\n",
    "                            H = panorama_cache[right]\n",
    "                        else:\n",
    "                            print('cache missed')\n",
    "                            H = get_H_matrix(scale_image(hole_filled_frames[right], scale_factor=1), scale_image(dst, scale_factor=1))\n",
    "                            panorama_cache[right] = H\n",
    "                        dst, shifted_H = stitch(dst, hole_filled_frames[right], H)\n",
    "                        shifted_H_persist[(right, anchor_index)] = shifted_H\n",
    "                        right_cache.append(dst)\n",
    "                        right += right_step\n",
    "                else:\n",
    "                    if left >= 0:\n",
    "                        if left in panorama_cache:\n",
    "                            print('cache hit')\n",
    "                            H = panorama_cache[left]\n",
    "                        else:\n",
    "                            print('cache missed')\n",
    "                            H = get_H_matrix(scale_image(hole_filled_frames[left], scale_factor=1), scale_image(dst, scale_factor=1))\n",
    "                            panorama_cache[left] = H\n",
    "                        dst, shifted_H = stitch(dst, hole_filled_frames[left], H)\n",
    "                        shifted_H_persist[(left, anchor_index)] = shifted_H\n",
    "                        left_cache.append(dst)\n",
    "                        left -= left_step\n",
    "                last_direction = not last_direction\n",
    "            return dst\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_panorama_from_middle_to_both_sides(step=10, original_frames=None, hole_filled_frames=None, right_cache=None, left_cache=None, shifted_H_persist = False):\n",
    "#     # if original_frames is None:\n",
    "#     #     original_frames = read_frames(INPUT_VIDEO_PATH)\n",
    "#     if hole_filled_frames is None:\n",
    "#         hole_filled_frames = read_frames(HOLE_FILLED_BACKGROUND_VIDEO_PATH)\n",
    "#     # if len(hole_filled_frames) != len(original_frames):\n",
    "#     #     raise IndexError(\"original frames and hole_filled background frames have different length! {}, {}\".format(len(original_frames), len(hole_filled_frames)))\n",
    "#     if shifted_H_persist:\n",
    "#         holder = {}\n",
    "    \n",
    "#     try:\n",
    "#         with shelve.open(writeback=True, filename=H_PERSIST_FILENAME) as d:\n",
    "#             # using original video H cache\n",
    "#             if FILENAME not in d:\n",
    "#                 d[FILENAME] = {}\n",
    "#             if 'original' not in d[FILENAME]:\n",
    "#                 d[FILENAME]['original'] = {}\n",
    "#             m = d[FILENAME]['original']\n",
    "#             anchor_index = len(hole_filled_frames) // 2\n",
    "\n",
    "#             dst = hole_filled_frames[anchor_index].copy()\n",
    "#             left = anchor_index - step\n",
    "#             right = anchor_index + step\n",
    "#             last_direction = False\n",
    "#             padding = [0] * 4\n",
    "#             count = 1\n",
    "#             while left >= 0 or right < len(hole_filled_frames):\n",
    "#                 print('iteration {}, time: {}'.format(count, time.time()))\n",
    "#                 count += 1\n",
    "#                 # right, left, right, left pattern\n",
    "#                 if not last_direction:\n",
    "#                     if right < len(hole_filled_frames):\n",
    "#                         dst, padding = tmp_worker(dst, hole_filled_frames[right], get_H_matrix(scale_image(hole_filled_frames[right], scale_factor=1), scale_image(dst, scale_factor=1)))\n",
    "#                         right_cache.append(dst)\n",
    "#                         right += step\n",
    "#                 else:\n",
    "#                     if left >= 0:\n",
    "#                         dst, padding = tmp_worker(dst, hole_filled_frames[left], get_H_matrix(scale_image(hole_filled_frames[left], scale_factor=1), scale_image(dst, scale_factor=1)))\n",
    "#                         left_cache.append(dst)\n",
    "#                         left -= step\n",
    "#                 last_direction = not last_direction\n",
    "#             return dst, padding\n",
    "#     except KeyboardInterrupt:\n",
    "#         print('Interrupted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with shelve.open(writeback=True, filename=H_PERSIST_FILENAME) as d:\n",
    "    d.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1, time: 1670556383.5891812\n",
      "cache missed\n",
      "iteration 2, time: 1670556386.7917035\n",
      "cache missed\n",
      "iteration 3, time: 1670556390.0528283\n",
      "cache missed\n",
      "iteration 4, time: 1670556393.313234\n",
      "cache missed\n",
      "iteration 5, time: 1670556396.3712335\n",
      "cache missed\n",
      "iteration 6, time: 1670556399.839995\n",
      "cache missed\n",
      "iteration 7, time: 1670556403.0646582\n",
      "cache missed\n",
      "iteration 8, time: 1670556406.6185622\n",
      "cache missed\n",
      "iteration 9, time: 1670556410.1721678\n",
      "cache missed\n",
      "iteration 10, time: 1670556413.6592703\n",
      "cache missed\n",
      "iteration 11, time: 1670556416.9512503\n",
      "cache missed\n",
      "iteration 12, time: 1670556421.3692458\n",
      "cache missed\n",
      "iteration 13, time: 1670556425.517329\n",
      "cache missed\n",
      "iteration 14, time: 1670556430.0081985\n",
      "cache missed\n",
      "iteration 15, time: 1670556434.2537668\n",
      "cache missed\n",
      "iteration 16, time: 1670556438.8662415\n",
      "cache missed\n",
      "iteration 17, time: 1670556443.24675\n",
      "cache missed\n",
      "iteration 18, time: 1670556448.073892\n",
      "cache missed\n",
      "iteration 19, time: 1670556452.28196\n",
      "cache missed\n",
      "iteration 20, time: 1670556457.2811534\n",
      "cache missed\n",
      "iteration 21, time: 1670556461.9557939\n",
      "cache missed\n",
      "iteration 22, time: 1670556466.6435108\n",
      "cache missed\n",
      "iteration 23, time: 1670556471.1792233\n",
      "cache missed\n"
     ]
    }
   ],
   "source": [
    "right_cache = []\n",
    "left_cache = []\n",
    "shifted_H_holder = {}\n",
    "anchor_index = -1\n",
    "panorama = generate_panorama_from_middle_to_both_sides(shifted_H_holder, left_step = 5, right_step = 5,\n",
    "             right_cache=right_cache, left_cache=left_cache, clear_cache=True, anchor_index = anchor_index)\n",
    "# panorama, shifted_H_holder = generate_panorama_from_middle_to_both_sides(step = 30, right_cache=right_cache, left_cache=left_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('adf', scale_to_1920_1080(panorama))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "with shelve.open(writeback=True, filename='shifted_H_persist') as d:\n",
    "    if FILENAME not in d:\n",
    "        d[FILENAME] = {}\n",
    "    m = d[FILENAME]\n",
    "    m[anchor_index] = shifted_H_holder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "for left in left_cache:\n",
    "    cv.imshow('adf', scale_to_1920_1080(left))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for right in right_cache:\n",
    "    cv.imshow('adf', scale_to_1920_1080(right))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with shelve.open(writeback=True, filename=H_PERSIST_FILENAME) as d:\n",
    "    # using original video H cache\n",
    "    if FILENAME not in d:\n",
    "        d[FILENAME] = {}\n",
    "    if 'original' not in d[FILENAME]:\n",
    "        d[FILENAME]['original'] = {}\n",
    "    m = d[FILENAME]['original']\n",
    "    original_frames = read_frames(INPUT_VIDEO_PATH)\n",
    "    Hs = []\n",
    "    for i in range(10):\n",
    "        Hs.append(get_H_matrix_cached_version(i, i + 1,original_frames[i], original_frames[i + 1], m))\n",
    "    H_direct = get_H_matrix_cached_version(0, 10, original_frames[0], original_frames[10], m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('asdf', scale_image(original_frames[0]))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Hs[-1]\n",
    "for h in Hs[-2:0:-1]:\n",
    "    a = a.dot(h)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 2560 / panorama.shape[1]\n",
    "resized_panorama = cv.resize(panorama, (int(panorama.shape[1] * scale), int(panorama.shape[0] * scale)))\n",
    "cv.imwrite(OUTPUT_PANORAMA_IMG_NAME, resized_panorama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for right, left in zip(right_cache, left_cache):\n",
    "    scale = 2560 / right.shape[1]\n",
    "    cv.imshow('asd', cv.resize(right, (int(right.shape[1] * scale), int(right.shape[0] * scale))))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    scale = 2560 / left.shape[1]\n",
    "    cv.imshow('adf', cv.resize(left, (int(left.shape[1] * scale), int(left.shape[0] * scale))))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for right, left in zip(right_cache, left_cache):\n",
    "    cv.imshow('asd', scale_to_1920_1080(right))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    cv.imshow('adf', scale_to_1920_1080(left))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv.VideoCapture(INPUT_VIDEO_PATH)\n",
    "# background_video_out = cv.VideoWriter(\"out/{}_filled_background_video.mp4\".format(FILENAME.split('.')[0]), cv.VideoWriter_fourcc(*'XVID'), int(cap.get(cv.CAP_PROP_FPS)),\n",
    "#                                 (int(cap.get(cv.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "frames = []\n",
    "for i in range(0, 404):\n",
    "    frames.append(cv.imread(\"out_images/out_images/{}_background_{}.jpg\".format(FILENAME.split('.')[0], i)))\n",
    "# cap.release()\n",
    "# background_video_out.release()\n",
    "\n",
    "# cv.destroyAllWindows()\n",
    "# cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cv.Stitcher.create(mode = cv.Stitcher_PANORAMA)\n",
    "pano = None\n",
    "def test(gap):\n",
    "    global pano\n",
    "    anchor_index = len(frames) // 2\n",
    "    left = anchor_index - gap\n",
    "    right = anchor_index + gap\n",
    "    last_direction = False\n",
    "    pano = frames[anchor_index]\n",
    "    try:\n",
    "        while left >= 0 or right < len(frames):\n",
    "            # right, left, right, left pattern\n",
    "            if not last_direction:\n",
    "                if right < len(frames):\n",
    "                    status, pano = s.stitch([pano, frames[right]])\n",
    "                    if status != 0:\n",
    "                        raise KeyError(\"{}\".format(status))\n",
    "                    right += gap\n",
    "            else:\n",
    "                if left >= 0:\n",
    "                    status, pano = s.stitch([pano, frames[left]])\n",
    "                    if status != 0:\n",
    "                        raise KeyError(\"{}\".format(status))\n",
    "                    left -= gap\n",
    "            last_direction = not last_direction\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted!\")\n",
    "test(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.estimateTransform([frames[0], frames[10]])\n",
    "s.composePanorama([frames[0], frames[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('asdf', pano)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panorama = generate_panorama(filled_frames, len(filled_frames) // 2)\n",
    "scale = 2560 / panorama.shape[1]\n",
    "resized_panorama = cv.resize(panorama, (int(panorama.shape[1] * scale), int(panorama.shape[0] * scale)))\n",
    "cv.imwrite(OUTPUT_PANORAMA_IMG_NAME, resized_panorama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('resized_panorama', resized_panorama)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cv.Stitcher.create(cv.Stitcher_PANORAMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dst_padded.shape)\n",
    "print(src_warped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (all([0, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from stitching import Stitcher\n",
    "\n",
    "# def generate_panorama(filled_frames):\n",
    "#     stitcher = Stitcher(filled_frames)\n",
    "\n",
    "#     # resize images\n",
    "#     stitcher.resize()\n",
    "\n",
    "#     # find features\n",
    "#     stitcher.find_features()\n",
    "\n",
    "#     # Match Features\n",
    "#     stitcher.match()\n",
    "\n",
    "#     # subset\n",
    "#     stitcher.subset()\n",
    "\n",
    "#     # camera Estimation\n",
    "#     stitcher.camera_correction()\n",
    "\n",
    "#     # warp image\n",
    "#     stitcher.wrap()\n",
    "\n",
    "#     # Seam Masks\n",
    "#     stitcher.seam()\n",
    "\n",
    "#     # Exposure Error Compensation\n",
    "#     stitcher.exposure_error_compensation()\n",
    "\n",
    "#     # Blending\n",
    "#     panorama = stitcher.blending()\n",
    "\n",
    "#     cv.imwrite(OUTPUT_PANORAMA_IMG_PATH, panorama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [cv.imread('out_images/out_images/{}_background_{}.jpg'.format(FILENAME.split('.')[0], i)) for i in range(404)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with shelve.open(writeback=True, filename='H_persist') as d:\n",
    "        if FILENAME not in d:\n",
    "            d[FILENAME] = {}\n",
    "        m = d[FILENAME]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_image(img, figsize_in_inches=(5, 5)):\n",
    "    fig, ax = plt.subplots(figsize=figsize_in_inches)\n",
    "    ax.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def get_image_paths(img_set):\n",
    "    return [str(path.relative_to('.')) for path in Path('tmp').rglob(f'{img_set}*')]\n",
    "img_set = get_image_paths('test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "            'try_use_gpu': True,\n",
    "            # 'warper_type':'plane',\n",
    "            # 'adjuster':'no',\n",
    "            # 'match_conf': 0.1\n",
    "            'crop': False,\n",
    "            # 'match_conf': 0.1\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Stitcher(**settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.initialize_registration(img_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = s.resize_medium_resolution()\n",
    "features = s.find_features(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = s.match_features(features)\n",
    "cameras = s.estimate_camera_parameters(features, matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = s.perform_wave_correction(cameras)\n",
    "s.estimate_scale(cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = s.resize_low_resolution(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks, corners, sizes = s.warp_low_resolution(images, cameras)\n",
    "s.estimate_exposure_errors(corners, images, masks)\n",
    "seam_masks = s.find_seam_masks(images, corners, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = s.resize_final_resolution()\n",
    "images, masks, corners, sizes = s.warp_final_resolution(images, cameras)\n",
    "s.set_masks(masks)\n",
    "images = s.compensate_exposure_errors(corners, images)\n",
    "seam_masks = s.resize_seam_masks(seam_masks)\n",
    "\n",
    "s.initialize_composition(corners, sizes)\n",
    "s.blend_images(images, seam_masks, corners)\n",
    "pano = s.create_final_panorama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('pano', pano)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate background panorama\n",
    "generate_panorama(filled_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def fill_hole(step):\n",
    "#     background_frames = read_frames(OUTPUT_BACKGROUND_VIDEO_PATH)\n",
    "#     print(len(background_frames))\n",
    "#     hole_filled_background_out = cv.VideoWriter(HOLE_FILLED_BACKGROUND_VIDEO_PATH, cv.VideoWriter_fourcc(*'XVID'), fps, (width, height))\n",
    "#     if not hole_filled_background_out.isOpened():\n",
    "#         raise IOError(\"cap init failed\")\n",
    "\n",
    "#     try:\n",
    "#         # i is frame index\n",
    "#         for i in tqdm(range(len(foreground_labels) - step)):        \n",
    "#             # label is current frame's foreground label set\n",
    "#             label = foreground_labels[i]\n",
    "#             for row, col in label:\n",
    "#                 # H = np.identity(3)\n",
    "#                 # done = False\n",
    "#                 # index = i\n",
    "#                 # while not done:\n",
    "#                 #     for _ in range(0, step):\n",
    "#                 #         if index >= len(Hs):\n",
    "#                 #             # if can't fill, just break\n",
    "#                 #             break\n",
    "#                 #         H = np.matmul(H, np.linalg.inv(Hs[index]))\n",
    "#                 #         index += 1\n",
    "\n",
    "#                 #     if index >= len(Hs):\n",
    "#                 #         break\n",
    "\n",
    "#                 #     [corresponding_row, corresponding_col, _] = np.matmul(H, np.array([row, col, 1]))\n",
    "#                 #     corresponding_row = round(corresponding_row)\n",
    "#                 #     corresponding_col = round(corresponding_col)\n",
    "#                 #     if corresponding_row >= 0 and corresponding_row < height and corresponding_col >= 0 and corresponding_col < width and \\\n",
    "#                 #                             (corresponding_row, corresponding_col) not in foreground_labels[index]:\n",
    "#                 #         background_frames[i][row][col] = background_frames[index][corresponding_row][corresponding_col].copy()\n",
    "#                 #     done = True\n",
    "#                 H = Hs[0]\n",
    "#                 [corresponding_row, corresponding_col, _] = np.matmul(H, np.array([row, col, 1]))\n",
    "#                 corresponding_row = round(corresponding_row)\n",
    "#                 corresponding_col = round(corresponding_col)\n",
    "#                 if corresponding_row >= 0 and corresponding_row < height and corresponding_col >= 0 and corresponding_col < width and \\\n",
    "#                                         (corresponding_row, corresponding_col) not in foreground_labels[step]:\n",
    "#                     background_frames[i][row][col] = background_frames[i + step][corresponding_row][corresponding_col].copy()\n",
    "#             hole_filled_background_out.write(background_frames[i])\n",
    "#             break\n",
    "\n",
    "#     except KeyboardInterrupt:\n",
    "#         print('Interrupted!')   \n",
    "    \n",
    "#     hole_filled_background_out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(np.array(choices[0])).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_differences.view([(f'f{i}',all_differences.dtype) for i in range(all_differences.shape[-1])])[...,0].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test = np.array([[[1, 1], [1, 2], [1, 996]],\n",
    "#                  [[1, 1], [2, 1], [1, 996]],\n",
    "#                  [[1, 1], [1, 2], [1, 996]],\n",
    "#                  [[1, 1], [1, 2], [1, 996]],\n",
    "#                  [[1, 1], [1, 2], [1, 996]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_macroblocks_vectors(flow, macroblock_size):\n",
    "    width = len(flow[0])\n",
    "    height = len(flow)\n",
    "\n",
    "    macroblocks = np.zeros(\n",
    "        (height // macroblock_size + int(height % macroblock_size != 0),\n",
    "        width // macroblock_size + int(width % macroblock_size != 0),\n",
    "                            2))\n",
    "    print(macroblocks.shape)\n",
    "    for y in range(0, height , macroblock_size):\n",
    "        for x in range(0, width, macroblock_size):\n",
    "\n",
    "            bw = macroblock_size if x + macroblock_size <= width else width - x\n",
    "            bh = macroblock_size if y + macroblock_size <= height else height - y\n",
    "            # current block\n",
    "            cur_block = np.array([ i[x:x+bw] for i in flow[y:y + bh]])\n",
    "            # get mean vector\n",
    "            # flatten current block to make process easier\n",
    "            mean = cur_block.reshape(-1, cur_block.shape[-1]).mean(axis = 0)\n",
    "            macroblocks[y//macroblock_size + int(y % macroblock_size != 0)][x//macroblock_size + int(x % macroblock_size != 0)] = mean\n",
    "\n",
    "    return macroblocks\n",
    "# flow0_macroblock = get_macroblocks_vectors(flows[-1], 16)\n",
    "# flow0_macroblock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert pixel flow to block flow\n",
    "block_flow = get_macroblocks_vectors(flows[-1], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total_k_means.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total_k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find mode\n",
    "# for row in flows[0]:\n",
    "#     u, c = np.unique(row, axis=0, return_counts=True)\n",
    "#     y = u[c == c.max()]\n",
    "#     print(y)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fgmasks = np.zeros((len(flows), 1080, 1920), np.uint8)\n",
    "# for flow in tqdm(range(len(flows))):\n",
    "#     for row in range(1080):\n",
    "#         for col in range(1920):\n",
    "#             dir_y,dir_x = flows[flow][row][col][0], flows[flow][row][col][1]\n",
    "#             if dir_y  <= 0.2:\n",
    "#                         fgmasks[flow, row, col] = 1\n",
    "#     cv.imshow(\"dasd\", frames[flow] * fgmasks[flow, :, :, np.newaxis])\n",
    "#     cv.waitKey(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total_inliers = np.array([tuple(inlier) for inlier in flows[-1].reshape(-1, flows[-1].shape[-1])])\n",
    "# total_k_means = KMeans(n_clusters=2, random_state=0).fit(total_inliers)\n",
    "# algorithm = {lloyd, elkan, auto, full}\n",
    "blocks_inliers = np.array([tuple(inlier) for inlier in block_flow.reshape(-1, block_flow.shape[-1])])\n",
    "blocks_k_means = KMeans(n_clusters=2, random_state=0).fit(blocks_inliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# frame must be the prev frame of label\n",
    "def separate(label, frame, block_flow_width, block_size):\n",
    "    foreground = np.ndarray(shape=frames[0].shape, dtype=np.uint8)\n",
    "    foreground.fill(255)\n",
    "    background = foreground.copy()\n",
    "\n",
    "    for i in range(len(label)):\n",
    "        # get the block position\n",
    "        block_y = i // block_flow_width\n",
    "        block_x = i % block_flow_width\n",
    "        for y in range(block_y * block_size, min((block_y + 1) * block_size, frame.shape[0])):\n",
    "            for x in range(block_x * block_size, min((block_x + 1) * block_size, frame.shape[1])):\n",
    "                if label[i]:\n",
    "                    foreground[y][x] = frame[y][x]\n",
    "                else:\n",
    "                    background[y][x] = frame[y][x]\n",
    "\n",
    "\n",
    "    return foreground, background\n",
    "\n",
    "foreground, background = separate(blocks_k_means.labels_, frames[-2], block_flow.shape[1], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv.imshow('Frame',foreground)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv.imshow('Frame',background)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv.imshow('Frame',foreground)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('Frame',background)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "66812e8b0b857e5f417bf2670963de607b2bb5750ad221c697d5d4c610f445e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
