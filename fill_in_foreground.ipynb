{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VQF9cOrF-EH-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "from carvekit.api.high import HiInterface\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from carvekit.api.interface import Interface\n",
    "from carvekit.ml.wrap.fba_matting import FBAMatting\n",
    "from carvekit.ml.wrap.tracer_b7 import TracerUniversalB7\n",
    "from carvekit.ml.wrap.u2net import U2NET\n",
    "from carvekit.pipelines.postprocessing import MattingMethod\n",
    "from carvekit.pipelines.preprocessing import PreprocessingStub\n",
    "from carvekit.trimap.generator import TrimapGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# manual\n",
    "# Check doc strings for more information\n",
    "object_type = \"object\"\n",
    "_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if object_type == 'hair_like':\n",
    "    seg_net = U2NET(device=_device, batch_size=5,\n",
    "                    input_image_size=320, fp16=True)\n",
    "else:\n",
    "    seg_net = TracerUniversalB7(\n",
    "        device=_device, batch_size=5, input_image_size=640, fp16=True)\n",
    "\n",
    "\n",
    "fba = FBAMatting(device=_device,\n",
    "                 input_tensor_size=2048,\n",
    "                 batch_size=1)\n",
    "\n",
    "trimap = TrimapGenerator(prob_threshold=231,\n",
    "                         kernel_size=30,\n",
    "                         erosion_iters=5)\n",
    "\n",
    "preprocessing = PreprocessingStub()\n",
    "\n",
    "postprocessing = MattingMethod(matting_module=fba,\n",
    "                               trimap_generator=trimap,\n",
    "                               device=_device)\n",
    "interface = Interface(pre_pipe=preprocessing,\n",
    "                      post_pipe=postprocessing,\n",
    "                      seg_pipe=seg_net)\n",
    "\n",
    "# image = Image.open('SAL_images_per_60/SAL_23.jpg')\n",
    "# foreground = interface([image])[0]\n",
    "# foreground.save('from_code_manual.png')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# input video path\n",
    "DIR_PATH = 'videos'\n",
    "FILENAME = 'test3.mp4'\n",
    "INPUT_VIDEO_PATH = os.path.join(DIR_PATH, FILENAME)\n",
    "OUTPUT_PATH = 'out'\n",
    "\n",
    "OUTPUT_FOREGROUND_VIDEO_NAME = FILENAME.split('.')[0] + '_foreground.mp4'\n",
    "OUTPUT_BACKGROUND_VIDEO_NAME = FILENAME.split('.')[0] + '_background.mp4'\n",
    "OUTPUT_PANORAMA_IMG_NAME = FILENAME.split('.')[0] + '_panorama.jpg'\n",
    "HOLE_FILLED_BACKGROUND_VIDEO_NAME = 'hole_filled_' + FILENAME.split('.')[0] + '_background.mp4'\n",
    "\n",
    "OUTPUT_FOREGROUND_VIDEO_PATH = os.path.join(OUTPUT_PATH, OUTPUT_FOREGROUND_VIDEO_NAME)\n",
    "OUTPUT_BACKGROUND_VIDEO_PATH = os.path.join(OUTPUT_PATH, OUTPUT_BACKGROUND_VIDEO_NAME)\n",
    "OUTPUT_PANORAMA_IMG_PATH = os.path.join(OUTPUT_PATH, OUTPUT_PANORAMA_IMG_NAME)\n",
    "HOLE_FILLED_BACKGROUND_VIDEO_PATH = os.path.join(OUTPUT_PATH, HOLE_FILLED_BACKGROUND_VIDEO_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def read_frames(path):\n",
    "    \"\"\"\n",
    "    return video frames\n",
    "    \"\"\"\n",
    "    cap = cv.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Open video failed!\")\n",
    "\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            break\n",
    "\n",
    "        frames.append(frame)\n",
    "        \n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture(INPUT_VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Open video failed!\")\n",
    "\n",
    "fps = int(cap.get(cv.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "cap.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_foreground_labels(path, early_quit_frame_number=math.inf, early_quit_time=None):\n",
    "    cap = cv.VideoCapture(path)\n",
    "    if not cap.isOpened:\n",
    "        raise IOError(\"Open video failed!\")\n",
    "\n",
    "    foreground_labels = []\n",
    "    startTime = time.time()\n",
    "    try:\n",
    "        for _ in tqdm(range(int(min(cap.get(cv.CAP_PROP_FRAME_COUNT), early_quit_frame_number)))):\n",
    "            if early_quit_time and time.time() - startTime > early_quit_time:\n",
    "                break\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                raise IOError(\"Read frame failed!\")\n",
    "                \n",
    "            frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame, mode=\"RGB\")\n",
    "            resImg = interface([image])[0]\n",
    "            foreground = np.asarray(resImg)\n",
    "            foreground_label = set()\n",
    "            for i in range(len(foreground)):\n",
    "                for j in range(len(foreground[0])):\n",
    "                    if foreground[i][j][-1] != 0:\n",
    "                        foreground_label.add((i, j))\n",
    "            foreground_labels.append(foreground_label)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')    \n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    return foreground_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # save foreground labels\n",
    "# foreground_label_persistence_file = '{}_foreground_labels.npy'.format(FILENAME.split('.')[0])\n",
    "# np.save(foreground_label_persistence_file, [list(label) for label in foreground_labels])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# load foreground_labels\n",
    "foreground_label_persistence_file = '{}_foreground_labels.npy'.format(FILENAME.split('.')[0])\n",
    "foreground_labels = np.load(foreground_label_persistence_file, allow_pickle=True)\n",
    "# convert foreground_labels to list of set\n",
    "foreground_labels = [set(_) for _ in foreground_labels]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def generate_foreground_background_videos(foreground_labels):\n",
    "    if not os.path.exists('out'):\n",
    "        os.makedirs('out')\n",
    "\n",
    "    cap = cv.VideoCapture(INPUT_VIDEO_PATH)\n",
    "    if not cap.isOpened:\n",
    "        raise IOError(\"Open video failed!\")\n",
    "\n",
    "    foreground_out = cv.VideoWriter(OUTPUT_FOREGROUND_VIDEO_PATH, cv.VideoWriter_fourcc(*'XVID'), int(cap.get(cv.CAP_PROP_FPS)),\n",
    "                                (int(cap.get(cv.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))))\n",
    "    background_out = cv.VideoWriter(OUTPUT_BACKGROUND_VIDEO_PATH, cv.VideoWriter_fourcc(*'XVID'), int(cap.get(cv.CAP_PROP_FPS)),\n",
    "                                (int(cap.get(cv.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))))\n",
    "    if not foreground_out.isOpened() or not background_out.isOpened():\n",
    "        raise IOError(\"Init videoWriter failed!\")\n",
    "\n",
    "    try:\n",
    "        for i in tqdm(range(len(foreground_labels))):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                raise IOError(\"Read frame failed!\")\n",
    "                \n",
    "            label = foreground_labels[i]\n",
    "            foreground = np.zeros_like(frame)\n",
    "            foreground.fill(255)\n",
    "            for (j, k) in label:\n",
    "                foreground[j][k] = frame[j][k]\n",
    "                frame[j][k] = [255,255,255]\n",
    "\n",
    "            foreground_out.write(foreground.copy())\n",
    "            background_out.write(frame.copy())\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')    \n",
    "\n",
    "    cap.release()\n",
    "    foreground_out.release()\n",
    "    background_out.release()\n",
    "    cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate_foreground_background_videos(foreground_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def get_H_matrix(img1, img2):\n",
    "    # minimum number of matches we want find between these two images\n",
    "    MIN_MATCH_COUNT = 10\n",
    "\n",
    "    # img1 = cv.imread('SAL_images_per_60/SAL_53.jpg',0)          # queryImage\n",
    "    # img2 = cv.imread('SAL_images_per_60/SAL_83.jpg',0) # trainImage\n",
    "    # img2_copy = img2.copy()\n",
    "    # img1_copy = img1.copy()\n",
    "\n",
    "    # prev, cur are frames\n",
    "    # initiate feature detector, currently use SIFT, may try orb later\n",
    "    sift = cv.SIFT_create()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    # kp1, des1 = sift.detectAndCompute(cv.cvtColor(img1.copy(), cv.COLOR_BGR2GRAY), None)\n",
    "    # kp2, des2 = sift.detectAndCompute(cv.cvtColor(img2.copy(), cv.COLOR_BGR2GRAY),None)\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        H, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "        # matchesMask = mask.ravel().tolist()\n",
    "        # h,w = img1.shape\n",
    "        # pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "        # dst = cv.perspectiveTransform(pts,H)\n",
    "        # img2 = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)\n",
    "    else:\n",
    "        raise ValueError( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "        # matchesMask = None\n",
    "\n",
    "    # draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "    #                singlePointColor = None,\n",
    "    #                matchesMask = matchesMask, # draw only inliers\n",
    "    #                flags = 2)\n",
    "    # img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "    # plt.imshow(img3, 'gray'),plt.show()\n",
    "\n",
    "\n",
    "    return H"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_all_H_matrix_per_step(INPUT_VIDEO_PATH, step = 1):\n",
    "    # step - 1 is the number of ignored frames between two frames that are used to compute H matrix\n",
    "    Hs = []\n",
    "    cap = cv.VideoCapture(INPUT_VIDEO_PATH)\n",
    "    if not cap.isOpened:\n",
    "        raise IOError(\"Open video failed!\")\n",
    "\n",
    "    ret, prev = cap.read()\n",
    "    if not ret:\n",
    "        raise IOError(\"Read frame failed!\")\n",
    "\n",
    "    try:\n",
    "        for i in tqdm(range(1, int(cap.get(cv.CAP_PROP_FRAME_COUNT)))):\n",
    "            ret, cur = cap.read()\n",
    "            if not ret:\n",
    "                raise IOError(\"Read frame failed!\")\n",
    "            \n",
    "            if i % step == 0:\n",
    "                Hs.append(get_H_matrix(prev, cur))\n",
    "                prev = cur\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')    \n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    return Hs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [00:35<00:02,  2.75s/it]\n"
     ]
    }
   ],
   "source": [
    "gap = 30\n",
    "\n",
    "def fill_holes(frames, frame_gap, foreground_labels):\n",
    "\n",
    "    filled_frames = []\n",
    "\n",
    "    for i in range(0, len(frames), frame_gap):\n",
    "\n",
    "        if i + frame_gap < len(frames):\n",
    "            im_be_filled = frames[i]\n",
    "            im_later = frames[i + frame_gap]\n",
    "            im_out = cv.warpPerspective(im_later, get_H_matrix(im_be_filled, im_later), (im_later.shape[1],im_later.shape[0]), flags=cv.WARP_INVERSE_MAP)\n",
    "            for j, k in foreground_labels[i]:\n",
    "                im_be_filled[j][k] = im_out[j][k]\n",
    "        else:\n",
    "            break\n",
    "        filled_frames.append(im_be_filled)\n",
    "        # cv.imshow(\"cur\", im_be_filled)\n",
    "        # cv.waitKey(0)\n",
    "    return filled_frames\n",
    "\n",
    "\n",
    "# filled_frames = fill_holes(read_frames(OUTPUT_BACKGROUND_VIDEO_PATH), gap, foreground_labels)\n",
    "\n",
    "\n",
    "def fill_holes():\n",
    "    frames = read_frames(OUTPUT_BACKGROUND_VIDEO_PATH)\n",
    "    filled_frames = []\n",
    "\n",
    "    if len(frames) != len(foreground_labels):\n",
    "        raise EOFError(\"fasudf\")\n",
    "\n",
    "    for i in tqdm(range(0, len(frames), gap)):\n",
    "        cur_label = foreground_labels[i].copy()\n",
    "        last_index = i\n",
    "        if last_index + gap < len(frames):\n",
    "        # while len(cur_label) > 0:\n",
    "        #     print(len(cur_label))\n",
    "            # im_out = cv.warpPerspective(frames[last_index + gap], get_H_matrix(frames[i], frames[last_index + gap]), \\\n",
    "            #     (frames[i].shape[1], frames[i].shape[0]), flags=cv.WARP_INVERSE_MAP)\n",
    "            # convert to list due to the need to remove while iterating\n",
    "            if last_index + gap >= len(frames):\n",
    "                break\n",
    "            next_label = foreground_labels[last_index + gap]\n",
    "            srcs = [list(t) for t in cur_label]\n",
    "            # point x = j, y = i, so reverse below in a[::-1]\n",
    "            #perspectivetransform needs 3 dimensions, so we must manually wrap a nonsense dimension to make below 1 * N * 2\n",
    "            srcpts = np.array([[a[::-1] for a in srcs]]).astype(np.float32)\n",
    "            H = get_H_matrix(frames[i], frames[last_index + gap])\n",
    "            dstpts = np.rint(cv.perspectiveTransform(srcpts, H)[0]).astype(int)\n",
    "            for (x, y), (corresponding_x, corresponding_y) in zip(np.rint(srcpts[0]).astype(int), dstpts):\n",
    "                if (corresponding_y, corresponding_x) not in next_label and 0 <= corresponding_x < width and 0 <= corresponding_y < height:\n",
    "                    cur_label.remove((y, x))\n",
    "                    frames[i][y][x] = frames[last_index + gap][corresponding_y][corresponding_x]\n",
    "            last_index += gap\n",
    "        else:\n",
    "            break\n",
    "        filled_frames.append(frames[i])\n",
    "\n",
    "        # else:\n",
    "        #     while len(cur_label) > 0:\n",
    "        #         print(len(cur_label))\n",
    "        #         # im_out = cv.warpPerspective(frames[last_index + gap], get_H_matrix(frames[i], frames[last_index + gap]), \\\n",
    "        #         #     (frames[i].shape[1], frames[i].shape[0]), flags=cv.WARP_INVERSE_MAP)\n",
    "        #         # convert to list due to the need to remove while iterating\n",
    "        #         if last_index - gap < 0:\n",
    "        #             break\n",
    "        #         next_label = foreground_labels[last_index - gap]\n",
    "        #         srcs = [list(t) for t in cur_label]\n",
    "        #         H = get_H_matrix(frames[i], frames[last_index - gap])\n",
    "        #         for row, col in srcs:\n",
    "        #             [corresponding_row, corresponding_col, _] = np.matmul(H, np.array([row, col, 1]))\n",
    "        #             corresponding_row = round(corresponding_row)\n",
    "        #             corresponding_col = round(corresponding_col)\n",
    "        #             if (corresponding_row, corresponding_col) not in next_label and 0 <= corresponding_row < height and 0 <= corresponding_col < width:\n",
    "        #                 cur_label.remove((row, col))\n",
    "        #                 frames[i][row][col] = frames[last_index - gap][corresponding_row][corresponding_col]\n",
    "        #         last_index -= gap\n",
    "\n",
    "        # else:\n",
    "        #     if i - gap < 0:\n",
    "        #         raise IOError(\"Filled Error!\")\n",
    "        #     im_out = cv.warpPerspective(frames[i - gap], Hs[(i - gap) % gap], (im_later.shape[1],im_later.shape[0]))\n",
    "\n",
    "\n",
    "        # for j, k in foreground_labels[i]:\n",
    "        #         im_be_filled[j][k] = im_out[j][k]\n",
    "        # filled_frames.append(im_be_filled)\n",
    "        # cv.imshow(\"cur\", im_be_filled)\n",
    "        # cv.waitKey(0)\n",
    "    return filled_frames\n",
    "\n",
    "\n",
    "# filled_frames = fill_holes()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def interpolate_foreground_on_panorama(panorama_img, foreground_labels_set):\n",
    "    # cv.resize(panorama_img, [int(round(panorama_img.shape[1] * 0.5)), int(round(panorama_img.shape[0] * 0.5))], interpolation=cv.INTER_LINEAR_EXACT)\n",
    "    for i in range(4, len(panorama_img) - 4):\n",
    "        for j in range(4, len(panorama_img[0]) - 4):\n",
    "            if panorama_img[i][j][0] == 255:\n",
    "                continue\n",
    "            if (i, j) in foreground_labels_set:\n",
    "                continue\n",
    "            fore_count = 0\n",
    "            cur_pix = np.array([0, 0, 0])\n",
    "            for m in range(i - 2, i + 3):\n",
    "                for n in range(j - 2, j + 3):\n",
    "                    if m == i and n == j:\n",
    "                        continue\n",
    "                    if (m, n) in foreground_labels_set:\n",
    "                        fore_count += 1\n",
    "                        cur_pix = np.add(cur_pix, panorama_img[m][n])\n",
    "            if fore_count >= 5:\n",
    "                panorama_img[i][j] = cur_pix / fore_count\n",
    "\n",
    "    # visited = set()\n",
    "    # for index in tqdm(foreground_labels_set):\n",
    "    #     for m in range(index[0] - 1, index[0] + 2):\n",
    "    #         for n in range(index[1] - 1, index[1] + 2):\n",
    "    #             if (m ,n) in visited:\n",
    "    #                 continue\n",
    "    #             cur_pix = np.array([0, 0, 0])\n",
    "    #             for a in range(m - 1, m + 2):\n",
    "    #                 for b in range(n - 1, n + 2):\n",
    "    #                     cur_pix = np.add(cur_pix, panorama_img[a][b])\n",
    "    #             panorama_img[m][n] = cur_pix / 15\n",
    "    #             visited.add((m, n))\n",
    "    # for i in tqdm(range(4, len(panorama_img) - 4)):\n",
    "    #     for j in range(4, len(panorama_img[0]) - 4):\n",
    "    #         if (i, j) not in foreground_labels_set:\n",
    "    #             continue\n",
    "    #         for a in range(i - 1, i + 2):\n",
    "    #             for b in range (j - 1, j + 2):\n",
    "    #                 if (a, b) in foreground_labels_set:\n",
    "    #                     continue\n",
    "    #                 cur_pix = np.array([0, 0, 0])\n",
    "    #                 for m in range(i - 2, i + 3):\n",
    "    #                     for n in range(j - 2, j + 3):\n",
    "    #                         if m == i and n == j:\n",
    "    #                             continue\n",
    "    #                         if (m, n) in foreground_labels_set:\n",
    "    #                             cur_pix = np.add(cur_pix, panorama_img[m][n])\n",
    "    #                 panorama_img[i][j] = cur_pix / 15\n",
    "    #                 foreground_labels_set.add((a, b))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def fill_in_foreground_and_generate_img(n):\n",
    "\n",
    "    cap = cv.VideoCapture(INPUT_VIDEO_PATH)\n",
    "    if not cap.isOpened:\n",
    "        raise IOError(\"Open video failed!\")\n",
    "\n",
    "    panorama = cv.imread(OUTPUT_PANORAMA_IMG_PATH)\n",
    "    panorama_foreground_set = set()\n",
    "    panorama_height = len(panorama)\n",
    "    panorama_width = len(panorama[0])\n",
    "    try:\n",
    "        for i in tqdm(range(1, int(cap.get(cv.CAP_PROP_FRAME_COUNT)))):\n",
    "            ret, prev = cap.read()\n",
    "            if not ret:\n",
    "                raise IOError(\"Read frame failed!\")\n",
    "\n",
    "            if i % n == 0:\n",
    "                H = get_H_matrix(prev, panorama)\n",
    "                cur_label = foreground_labels[i].copy()\n",
    "                srcs = [list(t) for t in cur_label]\n",
    "                srcpts = np.array([[a[::-1] for a in srcs]]).astype(np.float32)\n",
    "                dstpts = np.rint(cv.perspectiveTransform(srcpts, H)[0]).astype(int)\n",
    "                for (x, y), (corresponding_x, corresponding_y) in zip(np.rint(srcpts[0]).astype(int), dstpts):\n",
    "                    if 0 <= corresponding_x < panorama_width and 0 <= corresponding_y < panorama_height:\n",
    "                        panorama[corresponding_y][corresponding_x] = prev[y][x]\n",
    "                        panorama_foreground_set.add((corresponding_y, corresponding_x))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')\n",
    "\n",
    "    interpolate_foreground_on_panorama(panorama, panorama_foreground_set)\n",
    "        # cv.imshow(str(frame_count), prev)\n",
    "        # cv.waitKey(0)\n",
    "        # cv.destroyAllWindows()\n",
    "        # cv.waitKey(1)\n",
    "\n",
    "\n",
    "    cv.imshow('panorama', panorama)\n",
    "    cv.imwrite(os.path.join(OUTPUT_PATH, \"{}_panorama_output1.jpg\".format(FILENAME.split('.')[0])), panorama)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    cv.waitKey(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def fill_in_foreground_and_generate_video():\n",
    "\n",
    "    cap = cv.VideoCapture(INPUT_VIDEO_PATH)\n",
    "    if not cap.isOpened:\n",
    "        raise IOError(\"Open video failed!\")\n",
    "\n",
    "    panorama = cv.imread(OUTPUT_PANORAMA_IMG_PATH)\n",
    "    panorama_height = len(panorama)\n",
    "    panorama_width = len(panorama[0])\n",
    "    panorama_foreground_set = set()\n",
    "    panorama_video_out = cv.VideoWriter(\"out/panorama_video.mp4\", cv.VideoWriter_fourcc(*'XVID'), int(cap.get(cv.CAP_PROP_FPS)),\n",
    "                                (int(panorama_width), int(panorama_height)))\n",
    "    if not panorama_video_out.isOpened():\n",
    "        raise IOError(\"Init videoWriter failed!\")\n",
    "    try:\n",
    "        for i in tqdm(range(0, int(cap.get(cv.CAP_PROP_FRAME_COUNT)))):\n",
    "            ret, prev = cap.read()\n",
    "            if not ret:\n",
    "                raise IOError(\"Read frame failed!\")\n",
    "\n",
    "            panorama_foreground_set.clear()\n",
    "            cur_panorama = panorama.copy()\n",
    "            H = get_H_matrix(prev, cur_panorama)\n",
    "            cur_label = foreground_labels[i].copy()\n",
    "            srcs = [list(t) for t in cur_label]\n",
    "            srcpts = np.array([[a[::-1] for a in srcs]]).astype(np.float32)\n",
    "            dstpts = np.rint(cv.perspectiveTransform(srcpts, H)[0]).astype(int)\n",
    "            for (x, y), (corresponding_x, corresponding_y) in zip(np.rint(srcpts[0]).astype(int), dstpts):\n",
    "                if 0 <= corresponding_x < panorama_width and 0 <= corresponding_y < panorama_height:\n",
    "                    cur_panorama[corresponding_y][corresponding_x] = prev[y][x]\n",
    "                    panorama_foreground_set.add((corresponding_y, corresponding_x))\n",
    "\n",
    "            interpolate_foreground_on_panorama(cur_panorama, panorama_foreground_set)\n",
    "            panorama_video_out.write(cur_panorama)\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')\n",
    "\n",
    "\n",
    "        # cv.imshow(str(frame_count), prev)\n",
    "        # cv.waitKey(0)\n",
    "        # cv.destroyAllWindows()\n",
    "        # cv.waitKey(1)\n",
    "\n",
    "    cap.release()\n",
    "    panorama_video_out.release()\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    cv.waitKey(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def fill_in_foreground_and_generate_all_imgs(output_folder, start, end):\n",
    "    cap = cv.VideoCapture(INPUT_VIDEO_PATH)\n",
    "\n",
    "    if not cap.isOpened:\n",
    "        raise IOError(\"Open video failed!\")\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "    panorama = cv.imread(OUTPUT_PANORAMA_IMG_PATH)\n",
    "    panorama_height = len(panorama)\n",
    "    panorama_width = len(panorama[0])\n",
    "    panorama_foreground_set = set()\n",
    "    try:\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        if start >= int(cap.get(cv.CAP_PROP_FRAME_COUNT)):\n",
    "            return\n",
    "        if end > int(cap.get(cv.CAP_PROP_FRAME_COUNT)):\n",
    "            end = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "        for i in tqdm(range(0, int(cap.get(cv.CAP_PROP_FRAME_COUNT)))):\n",
    "            ret, prev = cap.read()\n",
    "            if not start <= i < end:\n",
    "                continue\n",
    "            # if not ret:\n",
    "            #     raise IOError(\"Read frame failed!\")\n",
    "\n",
    "            panorama_foreground_set.clear()\n",
    "            cur_panorama = panorama.copy()\n",
    "            H = get_H_matrix(prev, cur_panorama)\n",
    "            cur_label = foreground_labels[i].copy()\n",
    "            srcs = [list(t) for t in cur_label]\n",
    "            if len(srcs) != 0:\n",
    "                srcpts = np.array([[a[::-1] for a in srcs]]).astype(np.float32)\n",
    "                dstpts = np.rint(cv.perspectiveTransform(srcpts, H)[0]).astype(int)\n",
    "                for (x, y), (corresponding_x, corresponding_y) in zip(np.rint(srcpts[0]).astype(int), dstpts):\n",
    "                    if 0 <= corresponding_x < panorama_width and 0 <= corresponding_y < panorama_height:\n",
    "                        cur_panorama[corresponding_y][corresponding_x] = prev[y][x]\n",
    "                        panorama_foreground_set.add((corresponding_y, corresponding_x))\n",
    "\n",
    "                interpolate_foreground_on_panorama(cur_panorama, panorama_foreground_set)\n",
    "            cv.imwrite(f\"{output_folder}/{FILENAME.split('.')[0]}_panorama_with_foreground_{i}.jpg\", cur_panorama)\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')\n",
    "\n",
    "\n",
    "    cap.release()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 344/595 [1:12:44<53:04, 12.69s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fill_in_foreground_and_generate_all_imgs(\"output3_best\", 325, 350)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def create_app3_pre_video_from_img(img_folder):\n",
    "    if not os.path.exists(img_folder):\n",
    "        raise IOError(\"Open folder failed!\")\n",
    "    cap = cv.VideoCapture(INPUT_VIDEO_PATH)\n",
    "\n",
    "    panorama = cv.imread(OUTPUT_PANORAMA_IMG_PATH)\n",
    "    panorama_height = len(panorama)\n",
    "    panorama_width = len(panorama[0])\n",
    "    panorama_video_out = cv.VideoWriter(f\"out/{FILENAME.split('.')[0]}_application_2_pre_video.mp4\", cv.VideoWriter_fourcc(*'XVID'), int(cap.get(cv.CAP_PROP_FPS)), (int(panorama_width), int(panorama_height)))\n",
    "\n",
    "    try:\n",
    "        for i in tqdm(range(0, int(cap.get(cv.CAP_PROP_FRAME_COUNT)))):\n",
    "            cur_img_name = f\"{img_folder}/{FILENAME.split('.')[0]}_panorama_with_foreground_{i}.jpg\"\n",
    "            if os.path.isfile(cur_img_name):\n",
    "                panorama_video_out.write(cv.imread(cur_img_name))\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')\n",
    "    cap.release()\n",
    "    panorama_video_out.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 595/595 [00:40<00:00, 14.82it/s]\n"
     ]
    }
   ],
   "source": [
    "create_app3_pre_video_from_img(\"output3\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "33f5e31b291bd9d082e327c0f5837216cda17882beb8cb2127174aa38a1716b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}